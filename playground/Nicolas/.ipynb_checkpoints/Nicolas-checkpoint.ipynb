{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAT_VARS = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', \n",
    "            'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "            'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "            'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
    "            'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "            'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n",
    "            'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n",
    "            'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "            'MoSold', 'SaleType', 'SaleCondition']\n",
    "CONT_VARS = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "             'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "             'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "             'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "             'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "             'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold']\n",
    "\n",
    "TARGET_VAR = ['SalePrice',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummify(data):\n",
    "    cont = data[CONT_VARS]\n",
    "    cat = data[CAT_VARS]\n",
    "    for cat_var in CAT_VARS:\n",
    "        dummies = pd.get_dummies(data[cat_var], prefix=cat_var)\n",
    "        cat = cat.join(dummies)\n",
    "        del cat[cat_var]\n",
    "        \n",
    "    result = cat.join(cont)\n",
    "    \n",
    "    try:\n",
    "        result = result.join(data[TARGET_VAR])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1460, 314)\n",
      "test: (1459, 314)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Read in the data.\n",
    "train_df = pd.read_csv('../../data/train.csv')\n",
    "test_df = pd.read_csv('../../data/test.csv')\n",
    "\n",
    "train_df.set_index('Id', inplace=True)\n",
    "test_df.set_index('Id', inplace=True)\n",
    "\n",
    "# Assign category type to category variables\n",
    "for cat_var in CAT_VARS:\n",
    "    train_df[cat_var].astype('category')\n",
    "\n",
    "# Dummify: convert categorical to dummy\n",
    "train_df = dummify(train_df)\n",
    "test_df = dummify(test_df)\n",
    "\n",
    "# save feature variable labels\n",
    "VARS_X = list(train_df.columns)\n",
    "VARS_X.remove(TARGET_VAR[0])\n",
    "\n",
    "# Add missing columns in test set and fill with zeros\n",
    "cols_missing_in_test = set(VARS_X) - set(test_df.columns)\n",
    "for col in cols_missing_in_test:\n",
    "    test_df[col] = 0\n",
    "\n",
    "# Fill missing values with column mean\n",
    "train_df = train_df.fillna(train_df.mean())\n",
    "test_df = test_df.fillna(train_df.mean())\n",
    "\n",
    "# standardization\n",
    "scaler = preprocessing.StandardScaler().fit(train_df[VARS_X])\n",
    "train_df[VARS_X] = scaler.fit_transform(train_df[VARS_X])\n",
    "test_df[VARS_X] = scaler.fit_transform(test_df[VARS_X])\n",
    "\n",
    "\n",
    "# Get rid of outliers\n",
    "# ...\n",
    "\n",
    "print 'train:', train_df.shape\n",
    "print 'test:', test_df.shape\n",
    "\n",
    "# Create .csv with cleaned data\n",
    "train_df.to_csv('clean_train.csv', sept=',', index=False)\n",
    "test_df.to_csv('clean_test.csv', sept=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "(1168, 314)\n",
      "validation data:\n",
      "(292, 314)\n"
     ]
    }
   ],
   "source": [
    "# Get all the columns from the dataframe.\n",
    "columns = train_df.columns.tolist()\n",
    "columns.remove(TARGET_VAR[0])\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = TARGET_VAR[0]\n",
    "\n",
    "# Import a convenience function to split the sets.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Generate the training set.  Set random_state to be able to replicate results.\n",
    "# To Do: What does this frac thing do? Is this something we could optimize?\n",
    "train = train_df.sample(frac=0.8, random_state=1)\n",
    "# Select anything not in the training set and put it in the validation set.\n",
    "validation = train_df.loc[~train_df.index.isin(train.index)]\n",
    "# Print the shapes of both sets.\n",
    "\n",
    "print \"train data:\"\n",
    "print train.shape\n",
    "print \"validation data:\"\n",
    "print validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Test model on evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507650749.33918053"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the linearregression model.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model class.\n",
    "model = LinearRegression()\n",
    "# Fit the model to the training data.\n",
    "model.fit(train[columns], train[target])\n",
    "\n",
    "# Import the scikit-learn function to compute error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate our predictions for the validation set.\n",
    "predictions_val = model.predict(validation[columns])\n",
    "\n",
    "# Compute error between our validation predictions and the actual values.\n",
    "mean_squared_error(predictions_val, validation[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model to test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare test set:\n",
    "train_cols = set(columns)\n",
    "test_cols = set(test_df.columns.tolist())\n",
    "missing_train = test_cols - train_cols\n",
    "missing_test = train_cols - test_cols\n",
    "# (1) Delete columns which are missing in train_df\n",
    "test_df.drop(missing_train, axis=1, inplace=True)\n",
    "# (2) Create 0-filled columns which are missing in test_df\n",
    "for col in missing_test:\n",
    "    test_df[col] = 0\n",
    "\n",
    "# Generate our predictions for the test set.\n",
    "predictions_val = model.predict(test_df[columns])\n",
    "#print predictions_val\n",
    "\n",
    "idx = test_df.index.values\n",
    "\n",
    "submission = np.vstack((idx, predictions_val)).T\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(data=submission[0:, 0:],\n",
    "                          index=submission[0:, 0],\n",
    "                          columns=['Id', 'SalePrice'])\n",
    "\n",
    "submission.to_csv('submission.csv', sept=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model with some parameters.\n",
    "model = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=1)\n",
    "# Fit the model to the data.\n",
    "model.fit(train[columns], train[target])\n",
    "# Make predictions.\n",
    "predictions = model.predict(validation[columns])\n",
    "\n",
    "# Import the scikit-learn function to compute error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Compute the error.\n",
    "mean_squared_error(predictions, validation[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
